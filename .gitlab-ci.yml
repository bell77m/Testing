# GitLab CI/CD Pipeline with Test Management
# Features: Test stages, Allure reports, Slack notifications, Test metrics

image: mcr.microsoft.com/playwright/python:v1.57.0-jammy

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  ALLURE_RESULTS: "reports/allure-results"
  ALLURE_REPORT: "reports/allure-report"

stages:
  - install
  - lint
  - test_smoke
  - test_regression
  - test_security
  - report
  - deploy_report
  - notify

# Cache dependencies
cache:
  paths:
    - .cache/pip
    - .venv/

# ==================== Install Dependencies ====================
install_dependencies:
  stage: install
  script:
    - pip install --upgrade pip
    - pip install -r requirements.txt
    - playwright install --with-deps chromium
  artifacts:
    paths:
      - .venv/
    expire_in: 1 hour

# ==================== Code Quality ====================
lint_code:
  stage: lint
  script:
    - pip install black flake8 isort
    - echo "ðŸ“ Checking code formatting..."
    - black --check . --line-length=120 || echo "âš ï¸ Black formatting needed"
    - flake8 . --max-line-length=120 --ignore=E203,W503,E501 || echo "âš ï¸ Flake8 issues found"
    - isort --check-only . --profile=black --line-length=120 || echo "âš ï¸ Import sorting needed"
    - echo "âœ… Lint check complete (non-blocking)"
  allow_failure: true

# ==================== Auto-format Code (Optional) ====================
format_code:
  stage: lint
  script:
    - pip install black isort
    - echo "ðŸŽ¨ Auto-formatting code..."
    - black . --line-length=120
    - isort . --profile=black --line-length=120
    - echo "âœ… Code formatted"
    # Show what changed
    - git diff --stat || true
  when: manual  # Only run when manually triggered
  allow_failure: true

# ==================== Smoke Tests (Fast) ====================
smoke_tests:
  stage: test_smoke
  script:
    - pip install -r requirements.txt
    - playwright install --with-deps chromium
    - pytest tests/smoke/ -m smoke --alluredir=$ALLURE_RESULTS -v
  artifacts:
    when: always
    paths:
      - $ALLURE_RESULTS
    reports:
      junit: reports/junit.xml
    expire_in: 1 week
  only:
    - main
    - master
    - merge_requests
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure

# ==================== Regression Tests (Full Suite) ====================
regression_tests:
  stage: test_regression
  script:
    - pip install -r requirements.txt
    - playwright install --with-deps chromium
    - pytest tests/regression/ -m regression --alluredir=$ALLURE_RESULTS -v
  artifacts:
    when: always
    paths:
      - $ALLURE_RESULTS
      - logs/
    expire_in: 1 week
  only:
    - main
    - master
    - schedules  # For nightly runs
  allow_failure: true

# ==================== Security Tests ====================
security_tests:
  stage: test_security
  script:
    - pip install -r requirements.txt
    - playwright install --with-deps chromium
    - pytest -m security --alluredir=$ALLURE_RESULTS -v
  artifacts:
    when: always
    paths:
      - $ALLURE_RESULTS
    expire_in: 1 week
  only:
    - schedules
  allow_failure: true

# ==================== Generate Allure Report ====================
generate_allure_report:
  stage: report
  image: frankescobar/allure-docker-service:latest
  script:
    - allure generate $ALLURE_RESULTS --clean -o $ALLURE_REPORT
  artifacts:
    paths:
      - $ALLURE_REPORT
    expire_in: 30 days
  when: always
  dependencies:
    - smoke_tests
    - regression_tests
    - security_tests

# ==================== Deploy Report to GitLab Pages ====================
pages:
  stage: deploy_report
  script:
    - mkdir -p public
    - cp -r $ALLURE_REPORT/* public/ || echo "No Allure report to copy"
  artifacts:
    paths:
      - public
    expire_in: 30 days
  only:
    - main
    - master
  when: always

# ==================== Calculate Test Metrics ====================
test_metrics:
  stage: report
  image: python:3.11
  script:
    - pip install junitparser
    # Create scripts directory if it doesn't exist
    - mkdir -p scripts
    # Check if script exists, if not create a basic one
    - |
      if [ ! -f scripts/calculate_metrics.py ]; then
        echo "âš ï¸  Metrics script not found, creating basic version..."
        cat > scripts/calculate_metrics.py << 'EOFPYTHON'
      #!/usr/bin/env python3
      import sys
      from pathlib import Path
      
      print("ðŸ“Š Test Metrics Calculator")
      print("=" * 60)
      
      allure_results = Path("reports/allure-results")
      
      if not allure_results.exists():
          print("âš ï¸  No test results found")
          Path("metrics.txt").write_text("test_total 0\ntest_passed 0\ntest_failed 0\n")
          sys.exit(0)
      
      result_files = list(allure_results.glob("*-result.json"))
      total = len(result_files)
      
      print(f"Found {total} test result(s)")
      print("=" * 60)
      
      # Write basic metrics
      Path("metrics.txt").write_text(f"test_total {total}\n")
      print("âœ… Basic metrics generated")
      EOFPYTHON
        chmod +x scripts/calculate_metrics.py
      fi
    - python scripts/calculate_metrics.py || echo "Metrics calculation completed with warnings"
  artifacts:
    reports:
      metrics: metrics.txt
    paths:
      - metrics.txt
      - test-summary.json
      - test-summary.md
    expire_in: 30 days
  when: always
  allow_failure: true

# ==================== Generate Markdown Reports ====================
generate_reports:
  stage: report
  image: python:3.11
  before_script:
    # Install Pandoc
    - apt-get update
    - apt-get install -y pandoc texlive-latex-base texlive-fonts-recommended || true
    - pip install -r requirements.txt
  script:
    # Create scripts directory if needed
    - mkdir -p scripts utils docs/generated_reports

    # Create generate_reports.py if it doesn't exist
    - |
      if [ ! -f scripts/generate_reports.py ]; then
        echo "âš ï¸  Report generator not found, skipping..."
        exit 0
      fi

    # Run report generation
    - python scripts/generate_reports.py || echo "Report generation completed with warnings"
  artifacts:
    paths:
      - docs/generated_reports/
      - docs/*.md
    expire_in: 30 days
  when: always
  allow_failure: true
  dependencies:
    - smoke_tests
    - regression_tests
    - security_tests

# ==================== Merge Request Summary ====================
mr_summary:
  stage: report
  image: python:3.11
  script:
    - |
      if [ -f test-summary.md ]; then
        echo "ðŸ“Š Test Summary:"
        cat test-summary.md
      else
        echo "âš ï¸  No test summary available"
      fi
  only:
    - merge_requests
  when: always
  allow_failure: true
